---
title: "Modelling"
author: "Linus Hagemann"
date: "9/25/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(dplyr)
library(rsq)
library(here)
library(corrplot)
library(Hmisc)
library(rcompanion)
library(pscl)
library(olsrr)
library (psych)
load(here('prod.RData'))
# otherwise log transformation fails
# data <- data[data$author_follower_count > 0,]
# TODO: fixme and put in a nice place
# save(data, file = here('prod.RData'))
```

```{r}
# exclude all tweets that were retweeted more than a day after their creation
# as information diffusion is normally largely conmplete within 1-2 hours, these are outliers
# the retweet timelag is in seconds
data <- data[data$retweet_timelag < 86400,]
# subsample of all tweets that are retweetet at least once in order to
# check assumptions/statistics on this subsample as well
data_subset_retweetet <- data[data$retweet_count > 0,]
```


```{r include=FALSE}
# # merge with liwc data
# liwc_data <- read.csv(here('liwc.csv'))
# data <- cbind(data, liwc_data)
# data$negemo <- gsub(",",".", data$negemo)
# data$posemo <- gsub(",", ".", data$posemo)
# data$negemo <- as.numeric(data$negemo)
# data$posemo <- as.numeric(data$posemo)
# data$total_liwc_sentiment <- data$negemo + data$posemo
# save(data, file= here('prod.RData'))
# data$Tone <- gsub(",", ".", data$Tone)
# data$Tone <- as.numeric(data$Tone)
# data$author_verified <- ifelse(data$author_verified == "True", TRUE, FALSE)
# data$is_Negative <- as.numeric(data$is_Negative)
# data$author_verified <- as.numeric(data$author_verified)
```

# Descriptive statistics

```{r}
describe(data[, c("retweet_count", "sentiment", "hashtag_count", "url_existence", "user_activity", "author_follower_count", "author_verified", "retweet_timelag", "total_liwc_sentiment")], trim = 0.2)
describe(data_subset_retweetet[, c("retweet_count", "sentiment", "hashtag_count", "url_existence", "user_activity", "author_follower_count", "author_verified", "retweet_timelag", "total_liwc_sentiment")], trim = 0.2)
```

## Histogram

```{r}
hist(data_subset_retweetet$retweet_timelag)
boxplot(data_subset_retweetet$retweet_count)
#hist(data$sentiment)# looks fine
#hist(data$hashtag_count) # looks fine 
#hist(data$url_existence)# looks fine
#hist(data$user_activity)# looks fine
#hist(data$author_follower_count)# looks fine
#hist(data$total_liwc_sentiment)# looks fine
```

# Correlation Matrix of Independent Variables for all tweets
```{r}
used_subset <- select(data, sentiment, hashtag_count, url_existence, user_activity, author_follower_count, total_liwc_sentiment)
corrplot(cor(used_subset))
rcorr(as.matrix(used_subset))
```

# Correlation Matrix of Independent Variables for retweeted tweets

```{r}
used_subset <- select(data_subset_retweetet, sentiment, hashtag_count, url_existence, user_activity, author_follower_count, total_liwc_sentiment)
corrplot(cor(used_subset))
rcorr(as.matrix(used_subset))
```

# H1 with SentiStength

```{r H1}
h1 <- glm.nb(retweet_count ~ sentiment + hashtag_count + url_existence + log(user_activity) + log(author_follower_count) + author_verified, data = data)
summary(h1)
# adjusted r squared
# rsq(h1, adj = TRUE) # OA: the result looks suspicious 
# rsq(h1, adj = FALSE, type=c('lr')) # OA: mirrors Cox and Snell pseudo R2
# rsq(h1, adj = FALSE, type=c('n')) # OA: mirrors Nagelkerke pseudo R2
# LH: I suggest to just go with this function, as it gives us the most bang-for-the-buck :)
nagelkerke(h1) # the McFadden, Cox and Snell, and Nagelkerke pseudo R2 from the library(rcompanion)
# exponentiated coefficients for effectsize
exp(h1$coefficients)
odTest(h1)
```
Negative-binomial model instead of poisson is justified, i.e. count data is overdispersed. 

# H1 with LIWC data

```{r H1LIWC}
h1_liwc <- glm.nb(retweet_count ~ total_liwc_sentiment + hashtag_count + url_existence + log(user_activity) + log(author_follower_count) + author_verified, data = data)
summary(h1_liwc)
# adjusted r squared
nagelkerke(h1_liwc) 
# exponentiated coefficients for effectsize
exp(h1_liwc$coefficients)
odTest(h1_liwc)
```

# H2

## Regression with SentiStrength Data
```{r H2}
summary(h2<-lm(log(retweet_timelag) ~ sentiment + hashtag_count + url_existence + log(author_follower_count) + log(user_activity) + author_verified, data = data_subset_retweetet))
```

Detecting influential observations with Cook's distance
```{r}
cooksd <- cooks.distance(h2)
plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance")  # plot cook's distance
abline(h = 4*mean(cooksd, na.rm=T), col="red")  # add cutoff line
text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>5*mean(cooksd, na.rm=T),names(cooksd),""), col="red")  # add labels
influential <- as.numeric(names(cooksd)[(cooksd > 4*mean(cooksd, na.rm=T))])
length(influential)# 167 influential observations
#head(data[influential, ])  # influential observations.
```
## Regression with LIWC Data

```{r H2LIWC}
summary(h2_liwc<-lm(log(retweet_timelag) ~ total_liwc_sentiment + hashtag_count + url_existence + log(author_follower_count) + log(user_activity) + author_verified, data = data_subset_retweetet))
```

# H3A with SentiStrength Data

```{r include=FALSE}
# data$liwc_polarity <- data$posemo - data$negemo
# data$liwc_isNegative <- ifelse(data$liwc_polarity < 0, 1, 0)
# data$liwc_interaction_term <- data$liwc_isNegative * data$total_liwc_sentiment
# data$liwc_isNegative_tone <- ifelse(data$Tone < 0.5, 1, 0)
# data$liwc_interaction_term_tone <- data$liwc_isNegative_tone * data$Tone
```


```{r H3A}
h3a <- glm.nb(retweet_count ~ sentiment + is_Negative + interaction_term + hashtag_count + url_existence + log(user_activity) + log(author_follower_count) + author_verified, data = data)
summary(h3a)
# adjusted r squared
nagelkerke(h3a) 
# exponentiated coefficients for effectsize
exp(h3a$coefficients)
odTest(h3a)
```

# H3A with LIWC Data

```{r H3ALIWC}
h3a_liwc<- glm.nb(retweet_count ~ total_liwc_sentiment + liwc_isNegative + liwc_interaction_term + hashtag_count + url_existence + log(user_activity) + log(author_follower_count) + author_verified, data = data)
summary(h3a_liwc)
# adjusted r squared
nagelkerke(h3a_liwc) 
# exponentiated coefficients for effectsize
exp(h3a_liwc$coefficients)
odTest(h3a_liwc)
```

Output for overdispersion test should always be the same, as it depends on the dispersion of the retweet_count which is constant through all models. I have included it after every model just to make sure.

# H3B with SentiStrength Data

```{r H3B}
h3b <- lm(log(retweet_timelag) ~ sentiment + is_Negative + interaction_term + hashtag_count + url_existence + log(author_follower_count) + log(user_activity) + author_verified, data = data_subset_retweetet)
summary(h3b)
```

# H3B with LIWC Data
```{r H3BLIWC}
summary(lm(log(retweet_timelag) ~ total_liwc_sentiment + liwc_isNegative + liwc_interaction_term + hashtag_count + url_existence + log(author_follower_count) + log(user_activity) + author_verified, data = data_subset_retweetet))
```

# Diagnostic tests for the assumptions of linear regressions H2 & H3B

```{r}
plot(h2)
```
  
### Checking the regression model assumptions on residuals  
* 1.linearity  
In the "residuals vs. fitted" plot, the red line is almost lying near to zero residual value and is almost horizontal. The fitted values are scattered around the red line without any systematic relationship. Therefore, LINEARITY is met on residuals.   
* 2.normality    
In the q-q plot drawn, the e=residuals are almost linearly distributed. Checking normality using Shapiro-Wilk test (H0: residuals are normal), however, hints at non-normal distribution.
```{r}
shapiro.test(h2$residuals)
ols_test_normality(h2)
ols_plot_resid_hist(h2)
```
* 3.homoscadescity   
In scale-location plot, the residuals points are scattered, i.e., there seems to be no pattern that is not random. Hence, the variance is likely to be equal and HOMOSCADESCITY IS MET on residuals.  
* 4.independency    
We check whether the residuals are correlated (dependent) or not correlated (independent) by using Durbin-Watson test
```{r}
library(car)
durbinWatsonTest(h2)
```
Here, the probability value is smaller than 0.05,  so we reject the null hypothesis saying that there is no correlation among residuals(i.e residuals are independent). It's a pity :( 

**Conclusion**: despite some deviations in assumptions, in the large data sets like ours, most statistical methods rely on the Central Limit Theorem, which states that the average of a large number of independent random variables is approximately Normally distributed around the true population mean. Thus, we deemed to be confident in the validity of the estimations. 

# Comparison between LIWC and SentiStrength / Correlations
```{r}
#used_subset <- select(data, retweet_count, sentiment, hashtag_count, url_existence, user_activity, author_follower_count, author_verified, total_liwc_sentiment, retweet_timelag, liwc_isNegative, liwc_interaction_term, interaction_term, is_Negative)
#corrplot(cor(used_subset))
#rcorr(as.matrix(used_subset))
plot(data$total_liwc_sentiment, data$sentiment)
plot(data$negemo, data$posemo)
plot(data$Positive, data$Negative)
```

#CUT-OFFS
## Outliers 
```{r}
library(univOutl)
out_sentiment<-boxB(data[, c("sentiment")], k=3, method='asymmetric', weights=NULL, id=NULL,exclude=NA, logt=FALSE)

boxB(data[, c("retweet_count")], k=3, method='asymmetric', weights=NULL, id=NULL,exclude=NA, logt=FALSE)
boxB(data[, c("hashtag_count")], k=3, method='asymmetric', weights=NULL, id=NULL,exclude=NA, logt=FALSE)

out<-boxplot.stats(data$hashtag_count)$out
out_ind <- which(data$hashtag_count %in% c(out))
out_ind
boxplot(data$hashtag_count)
mtext(paste("Outliers: ", paste(out, collapse = ", ")))
datan<-data[, c("text", "retweet_count", "sentiment", "hashtag_count", "url_existence", "user_activity", "author_follower_count", "author_verified", "retweet_timelag", "total_liwc_sentiment")]
datan[54,1]
```
